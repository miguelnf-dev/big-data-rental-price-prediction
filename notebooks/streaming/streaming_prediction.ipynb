{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72b593d9-12d4-4f65-b154-81b7406c9a6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model..\n",
      "\n",
      "---------------Houses info-------------\n",
      "+------+----+-----+------------+------------+\n",
      "|sqfeet|beds|baths|cats_allowed|dogs_allowed|\n",
      "+------+----+-----+------------+------------+\n",
      "|   921|   2|    2|           0|           0|\n",
      "|  1090|   2|    2|           0|           0|\n",
      "|  1357|   3|    2|           1|           1|\n",
      "|  1038|   2|    2|           0|           0|\n",
      "|  1008|   2|    2|           1|           1|\n",
      "|   640|   1|    1|           1|           1|\n",
      "|   944|   2|    1|           1|           1|\n",
      "|  1700|   3|    2|           1|           1|\n",
      "|   780|   1|    1|           1|           1|\n",
      "|   864|   2|    2|           0|           0|\n",
      "+------+----+-----+------------+------------+\n",
      "\n",
      "---------------Rental price-------------\n",
      "\n",
      "House 1 is estimated to cost 1763.70$\n",
      "House 2 is estimated to cost 1864.25$\n",
      "House 3 is estimated to cost 2240.41$\n",
      "House 4 is estimated to cost 1882.66$\n",
      "House 5 is estimated to cost 1830.82$\n",
      "House 6 is estimated to cost 1439.62$\n",
      "House 7 is estimated to cost 1601.92$\n",
      "House 8 is estimated to cost 2314.98$\n",
      "House 9 is estimated to cost 1547.27$\n",
      "House 10 is estimated to cost 1792.95$\n",
      "\n",
      "Predictions saved to hdfs://10.84.129.52:9000/trab/g03/streaming/streaming_results/predictions.csv\n",
      "Waiting for file..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press any key to continue a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job ended\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from pyspark import SparkConf\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.types import IntegerType, FloatType, StringType\n",
    "from pyspark.ml import PipelineModel\n",
    "from pyspark import SparkConf\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.types import IntegerType, FloatType\n",
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.pipeline import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "import time\n",
    "\n",
    "# Create a SparkSession\n",
    "try:\n",
    "    spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
    "    sc = spark.sparkContext\n",
    "    streamingCont = StreamingContext(sc, 10)\n",
    "\n",
    "    # Load the pre-trained model\n",
    "    try:\n",
    "        model_path = \"CLUSTER_URL_HERE/model/model_rf_1687572265\"\n",
    "        model = PipelineModel.load(model_path)\n",
    "        print(\"Loaded model..\")\n",
    "        \n",
    "        \n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "    # Define a function to process each RDD\n",
    "    def process(rdd):\n",
    "        try:\n",
    "            count = rdd.count()\n",
    "            if count > 0:\n",
    "                # Split the input data into a list of values\n",
    "                rdd2 = rdd.map(lambda line: line.split(\",\"))\n",
    "\n",
    "                # Create a DataFrame from the input data\n",
    "                df = rdd2.map(lambda line: Row(sqfeet=line[6],\n",
    "                                beds=line[7],\n",
    "                                baths=line[8],\n",
    "                                cats_allowed=line[9],\n",
    "                                dogs_allowed=line[10])).toDF()\n",
    "                \n",
    "                # cast the data types of the columns\n",
    "                df = df.withColumn(\"sqfeet\", df[\"sqfeet\"].cast(IntegerType()))\\\n",
    "                       .withColumn(\"beds\", df[\"beds\"].cast(IntegerType()))\\\n",
    "                       .withColumn(\"baths\", df[\"baths\"].cast(IntegerType()))\\\n",
    "                       .withColumn(\"cats_allowed\", df[\"cats_allowed\"].cast(IntegerType()))\\\n",
    "                       .withColumn(\"dogs_allowed\", df[\"dogs_allowed\"].cast(IntegerType()))\\\n",
    "                \n",
    "                df = df.dropna()\n",
    "                print(\"---------------Houses info-------------\")\n",
    "                df.show()\n",
    "                \n",
    "                predictions = model.transform(df)\n",
    "                # select the prediction column and show the result for each row\n",
    "                results = predictions.select(\"prediction\").collect()\n",
    "                \n",
    "                print(\"---------------Rental price-------------\")\n",
    "                print()\n",
    "                for i, result in enumerate(results):    \n",
    "                    print(f\"House {i+1} is estimated to cost {result[0]:.2f} USD$\")\n",
    "                print()\n",
    "                \n",
    "                # Write the predictions to a file in HDFS\n",
    "                output_path = \"CLUSTER_URL_HERE/streaming/streaming_results/predictions.csv\"\n",
    "                predictions.select(\"prediction\").write.mode(\"overwrite\").csv(output_path)\n",
    "                print(f\"Predictions saved to {output_path}\")\n",
    "\n",
    "            else:\n",
    "                print(\"Waiting for file..\")\n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "\n",
    "    # Create a DStream from a text file\n",
    "    dstream = streamingCont.textFileStream(\"CLUSTER_URL_HERE\")\n",
    "    dstream.foreachRDD(process)\n",
    "\n",
    "    # Start the streaming context\n",
    "    streamingCont.start()\n",
    "    streamingCont.awaitTermination(timeout=1)\n",
    "\n",
    "except Exception as e:\n",
    "    print(str(e))\n",
    "\n",
    "# Stop the streaming context and SparkSession\n",
    "print(\"\")\n",
    "input('Press any key to continue')\n",
    "streamingCont.stop()\n",
    "spark.stop()\n",
    "print(\"job ended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c05e93-e128-4710-b706-dc14d31f57b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Stop the StreamingContext\n",
    "ssc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
